---
title: Real Time Facial Expression Recognition in Video using Active Shape Models and Support Vector Machines
layout: default
members: Rajat Vikram Singh
description: Machine Learning Course Project
category: project
---

Facial expression constitutes 55 percent of the effect of a communicated message and is hence a major modality in human communication. Literature establishes that there are six basic emotions that a person shows. Most of the emotions can be mapped as a combination of these emotions. These emotions are: Joy, Sad, Disgust, Anger, Surprise and Fear. A lot of different approaches exist in the literature to solve this problem. In the project, the 2003 ICMI paper titled - [[Real Time Facial Expression Recognition in Video using Support Vector Machines]](http://www.cs.cmu.edu/~cga/behavior/FER-SVM-ICMIpaper.pdf) by Michel at al. which talks about recognising facial expressions in real time video using support vector machines was implemented. The paper talks about using a Support Vector Machines on the features extracted from the consecutive frames of an expression making face. The paper used a propritery tracker to detect the facial features. Active Shape Models library [[Stasm]](http://www.milbo.users.sonic.net/stasm/) was used instead to find and track the facial features. [[Report]](/media/ExpressionDetection.pdf)